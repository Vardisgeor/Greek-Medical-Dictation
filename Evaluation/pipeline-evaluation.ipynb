{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Greek Medical Dictation Pipeline Evaluation\n","\n","This notebook evaluates the performance of three Whisper models (Small, Medium, and Large-v2) fine-tuned for Greek medical dictation, enhanced with a GPT-2 language model for transcription reranking. The goal is to assess transcription quality on a combined Greek audio dataset using standard metrics.\n","\n","## Objective\n","\n","* Evaluate ASR Performance: Compare the default Whisper transcriptions (greedy decoding) with GPT-2 reranked transcriptions.\n","* Metrics: Word Error Rate (WER), Normalized WER, Character Error Rate (CER), BLEU score, and perplexity.\n","* Dataset: A combined test set from \"Vardis/Greek_Mosel\", Common Voice (Greek), and Fleurs (Greek), standardized to 16kHz audio.\n","\n","\n","## Workflow\n","\n","### Dataset Preparation:\n","\n","* Load and split datasets: \"Vardis/Greek_Mosel\", Common Voice 11.0 (el), and Fleurs (el_gr).\n","Combine and shuffle train, validation, and test splits (80% train, 10% validation, 10% test).\n","Standardize audio to 16kHz and rename text fields to sentence.\n","\n","\n","### Model Setup:\n","\n","* Load fine-tuned Whisper models (Vardis/Whisper-Small-Greek, Vardis/Whisper-Medium-Greek, Vardis/Whisper-LoRA-Greek) with LoRA weights merged.\n","* Load GPT-2 model (Vardis/Medical_Speech_Greek_GPT2) for reranking.\n","Use torch.float16 and device_map=\"auto\" for GPU acceleration.\n","\n","\n","### Evaluation Process:\n","\n","* For each Whisper model (Small, Medium, Large-v2):\n","Generate default transcriptions (greedy decoding) and n-best hypotheses (beam search, n=5).\n","* Rerank hypotheses using GPT-2 perplexity scores.\n","* Compute WER, Normalized WER, CER, BLEU, and perplexity for default and reranked transcriptions.\n","\n","\n","### Results:\n","\n","* Report average metrics across the test set, comparing default and reranked performance.\n","Metrics include:\n","- WER: Word-level errors (standard and normalized).\n","- CER: Character-level errors.\n","- BLEU: Translation quality score.\n","- Perplexity: Language model confidence.\n","\n","\n","\n","This evaluation provides insights into the effectiveness of fine-tuned Whisper models and GPT-2 reranking for Greek medical dictation tasks.\n","\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2025-08-26T19:05:21.713028Z","iopub.status.busy":"2025-08-26T19:05:21.712843Z","iopub.status.idle":"2025-08-26T19:05:31.087471Z","shell.execute_reply":"2025-08-26T19:05:31.086543Z","shell.execute_reply.started":"2025-08-26T19:05:21.713010Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting evaluate\n","  Downloading evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\n","Collecting jiwer\n","  Downloading jiwer-4.0.0-py3-none-any.whl.metadata (3.3 kB)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\n","Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.4)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n","Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.5.1)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.33.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\n","Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.2.1)\n","Collecting rapidfuzz>=3.9.7 (from jiwer)\n","  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\n","Collecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)\n","  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.13)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.5)\n","Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\n","Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\n","Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\n","Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.2.0)\n","Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.2.0)\n","Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.6.15)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n","Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\n","Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.2.0)\n","Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.4.0)\n","Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\n","Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\n","Downloading evaluate-0.4.5-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jiwer-4.0.0-py3-none-any.whl (23 kB)\n","Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: rapidfuzz, fsspec, jiwer, evaluate\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2025.5.1\n","    Uninstalling fsspec-2025.5.1:\n","      Successfully uninstalled fsspec-2025.5.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","bigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n","cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n","gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n","bigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\n","bigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed evaluate-0.4.5 fsspec-2025.3.0 jiwer-4.0.0 rapidfuzz-3.13.0\n"]}],"source":["!pip install evaluate jiwer\n","!pip install datasets==3.6.0\n"]},{"cell_type":"markdown","metadata":{},"source":["## Load Dataset"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2025-08-26T19:05:31.088938Z","iopub.status.busy":"2025-08-26T19:05:31.088692Z","iopub.status.idle":"2025-08-26T19:08:28.887181Z","shell.execute_reply":"2025-08-26T19:08:28.886493Z","shell.execute_reply.started":"2025-08-26T19:05:31.088910Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2caccd24644d4f6985f494deff006481","version_major":2,"version_minor":0},"text/plain":["README.md:   0%|          | 0.00/322 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"79c350ed530a4c8f98fe18bdf1f2a952","version_major":2,"version_minor":0},"text/plain":["data/train-00000-of-00007.parquet:   0%|          | 0.00/497M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d054f82ffee04d2db81d433235484e56","version_major":2,"version_minor":0},"text/plain":["data/train-00001-of-00007.parquet:   0%|          | 0.00/494M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"74d6716dfdb54abdab79d0a0f9950a4f","version_major":2,"version_minor":0},"text/plain":["data/train-00002-of-00007.parquet:   0%|          | 0.00/498M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"59b496d79ead4a219609aa6b0d1dbb54","version_major":2,"version_minor":0},"text/plain":["data/train-00003-of-00007.parquet:   0%|          | 0.00/497M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fd66be5294384155a9196f7391716005","version_major":2,"version_minor":0},"text/plain":["data/train-00004-of-00007.parquet:   0%|          | 0.00/499M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4e7646b45db44070a1ad6ee979b01ed8","version_major":2,"version_minor":0},"text/plain":["data/train-00005-of-00007.parquet:   0%|          | 0.00/499M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2a3daf2d383d41a38f7a4373d2db3ab9","version_major":2,"version_minor":0},"text/plain":["data/train-00006-of-00007.parquet:   0%|          | 0.00/505M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"69cddd397486412fa9882aa010e55ef7","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/3876 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dfe36cc73d904d03ba933e5956f95262","version_major":2,"version_minor":0},"text/plain":["README.md: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"76c52877542c406bb90d4f79ca7c29cb","version_major":2,"version_minor":0},"text/plain":["common_voice_11_0.py: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2791e050f63f4fada2840181a8083028","version_major":2,"version_minor":0},"text/plain":["languages.py: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c85cf4f5100747c1b0cf3e755204cb9c","version_major":2,"version_minor":0},"text/plain":["release_stats.py: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["The repository for mozilla-foundation/common_voice_11_0 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mozilla-foundation/common_voice_11_0.\n","You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n","\n","Do you wish to run the custom code? [y/N]  y\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4f62446f2da644feb3d01ea26aad9e74","version_major":2,"version_minor":0},"text/plain":["n_shards.json: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f4cf96415f8b407bb5f2c9eb14a47581","version_major":2,"version_minor":0},"text/plain":["audio/el/train/el_train_0.tar:   0%|          | 0.00/57.4M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"adb6baa88f4c4747a435801aa0934079","version_major":2,"version_minor":0},"text/plain":["audio/el/dev/el_dev_0.tar:   0%|          | 0.00/51.0M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3b33a86505994f6dae7f413614dc30a1","version_major":2,"version_minor":0},"text/plain":["audio/el/test/el_test_0.tar:   0%|          | 0.00/50.9M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1b5acee626d84f7ab9ffcd0b50d59708","version_major":2,"version_minor":0},"text/plain":["audio/el/other/el_other_0.tar:   0%|          | 0.00/238M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7a4630f3f318422dba12df8f9b403bbf","version_major":2,"version_minor":0},"text/plain":["audio/el/invalidated/el_invalidated_0.ta(…):   0%|          | 0.00/23.3M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"68ed8f4aed904d3a949e364f964b84cc","version_major":2,"version_minor":0},"text/plain":["transcript/el/train.tsv:   0%|          | 0.00/482k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bb7ccee09bca40de8c4c93b0ff909160","version_major":2,"version_minor":0},"text/plain":["transcript/el/dev.tsv:   0%|          | 0.00/423k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e44b0d560bcc48cf80b0843a648738e9","version_major":2,"version_minor":0},"text/plain":["transcript/el/test.tsv:   0%|          | 0.00/410k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"af569cfe9d7f4b459ab0d1eb8bf4b4d5","version_major":2,"version_minor":0},"text/plain":["transcript/el/other.tsv:   0%|          | 0.00/2.22M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7f7e73d7c2af401f92cbf1fa95f2efd9","version_major":2,"version_minor":0},"text/plain":["transcript/el/invalidated.tsv:   0%|          | 0.00/201k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"72194020a5b4445290193d02d5580540","version_major":2,"version_minor":0},"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","Reading metadata...: 1914it [00:00, 142588.90it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0bfc18efe1f141d4b1004fc01418cc93","version_major":2,"version_minor":0},"text/plain":["Generating validation split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","Reading metadata...: 1701it [00:00, 133672.66it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1821fe7133984fa082776fed85c7fc9f","version_major":2,"version_minor":0},"text/plain":["Generating test split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","Reading metadata...: 1696it [00:00, 118481.98it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b9dda6e477aa41038a6f66c376cccf64","version_major":2,"version_minor":0},"text/plain":["Generating other split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","Reading metadata...: 9072it [00:00, 136668.60it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"007eee7a85c444b68a8d86db547eb1f6","version_major":2,"version_minor":0},"text/plain":["Generating invalidated split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","Reading metadata...: 797it [00:00, 113791.75it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"56933cc7db244ae297e84231171fcbc4","version_major":2,"version_minor":0},"text/plain":["README.md: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"62e1c05d6d1149849a3d89eff9a627ed","version_major":2,"version_minor":0},"text/plain":["fleurs.py: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["The repository for google/fleurs contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/google/fleurs.\n","You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n","\n","Do you wish to run the custom code? [y/N]  y\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"82322f205cc44d5791c8e263ec0d6204","version_major":2,"version_minor":0},"text/plain":["data/el_gr/audio/train.tar.gz:   0%|          | 0.00/1.91G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e0ce4a8f0b5a40e78d99024e8cda3796","version_major":2,"version_minor":0},"text/plain":["data/el_gr/audio/dev.tar.gz:   0%|          | 0.00/141M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6f7dde410b414732a9f3a904ea32fc3a","version_major":2,"version_minor":0},"text/plain":["data/el_gr/audio/test.tar.gz:   0%|          | 0.00/349M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0ea9727e849441b08ee9a60c032d7d9e","version_major":2,"version_minor":0},"text/plain":["train.tsv: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"400e9c35e209419da046c790716409a7","version_major":2,"version_minor":0},"text/plain":["dev.tsv: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"947cf340e4a24568956dda705b025c05","version_major":2,"version_minor":0},"text/plain":["test.tsv: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fc466ad6426c41149a98f5550f1a3a6b","version_major":2,"version_minor":0},"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"150c76473a6f470fafc8a3a062510c8d","version_major":2,"version_minor":0},"text/plain":["Generating validation split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"30dfb284f85b452990431dbe2d676ab5","version_major":2,"version_minor":0},"text/plain":["Generating test split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["IterableDatasetDict({\n","    train: Dataset({\n","        features: ['audio', 'sentence'],\n","        num_rows: 3100\n","    })\n","    validation: Dataset({\n","        features: ['audio', 'sentence'],\n","        num_rows: 388\n","    })\n","    test: Dataset({\n","        features: ['audio', 'sentence'],\n","        num_rows: 388\n","    })\n","})\n","IterableDatasetDict({\n","    train: Dataset({\n","        features: ['audio', 'sentence'],\n","        num_rows: 4248\n","    })\n","    validation: Dataset({\n","        features: ['audio', 'sentence'],\n","        num_rows: 531\n","    })\n","    test: Dataset({\n","        features: ['audio', 'sentence'],\n","        num_rows: 532\n","    })\n","})\n","IterableDatasetDict({\n","    train: Dataset({\n","        features: ['audio', 'sentence'],\n","        num_rows: 3308\n","    })\n","    validation: Dataset({\n","        features: ['audio', 'sentence'],\n","        num_rows: 414\n","    })\n","    test: Dataset({\n","        features: ['audio', 'sentence'],\n","        num_rows: 414\n","    })\n","})\n","IterableDatasetDict({\n","    train: Dataset({\n","        features: ['audio', 'sentence'],\n","        num_rows: 10656\n","    })\n","    validation: Dataset({\n","        features: ['audio', 'sentence'],\n","        num_rows: 1333\n","    })\n","    test: Dataset({\n","        features: ['audio', 'sentence'],\n","        num_rows: 1334\n","    })\n","})\n"]}],"source":["from datasets import load_dataset, IterableDatasetDict\n","import os\n","\n","\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","language = \"Greek\"\n","language_abbr = \"el\"\n","language_abbr2 = \"el_gr\"\n","task = \"transcribe\"\n","\n","\n","a = IterableDatasetDict()\n","b = IterableDatasetDict()\n","c = IterableDatasetDict()\n","\n","\n","a_full = load_dataset(\"Vardis/Greek_Mosel\", split=\"train\")\n","a_temp = a_full.train_test_split(test_size=0.2, seed=42)  # 80% train \n","a_val_test = a_temp[\"test\"].train_test_split(test_size=0.5, seed=42)  # 10% val + 10% test\n","a[\"train\"] = a_temp[\"train\"]\n","a[\"validation\"] = a_val_test[\"train\"]\n","a[\"test\"] = a_val_test[\"test\"]\n","\n","b_full = load_dataset(\"mozilla-foundation/common_voice_11_0\", language_abbr, split=\"train+validation+test\")\n","b_temp = b_full.train_test_split(test_size=0.2, seed=42)\n","b_val_test = b_temp[\"test\"].train_test_split(test_size=0.5, seed=42)\n","b[\"train\"] = b_temp[\"train\"]\n","b[\"validation\"] = b_val_test[\"train\"]\n","b[\"test\"] = b_val_test[\"test\"]\n","\n","c_full = load_dataset(\"google/fleurs\", language_abbr2, split=\"train+validation+test\")\n","c_temp = c_full.train_test_split(test_size=0.2, seed=42)\n","c_val_test = c_temp[\"test\"].train_test_split(test_size=0.5, seed=42)\n","c[\"train\"] = c_temp[\"train\"]\n","c[\"validation\"] = c_val_test[\"train\"]\n","c[\"test\"] = c_val_test[\"test\"]\n","\n","\n","\n","b = b.remove_columns([\"accent\", \"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"path\", \"segment\", \"up_votes\"])\n","c = c.remove_columns([\"id\", \"num_samples\", \"path\", \"raw_transcription\", \"gender\", \"lang_id\", \"language\", \"lang_group_id\"])\n","\n","a = a.rename_column(\"text\", \"sentence\")\n","c = c.rename_column(\"transcription\", \"sentence\")\n","\n","\n","print(a)\n","print(b)\n","print(c)\n","\n","from datasets import Audio\n","\n","a = a.cast_column(\"audio\", Audio(sampling_rate=16000))\n","b = b.cast_column(\"audio\", Audio(sampling_rate=16000))\n","c = c.cast_column(\"audio\", Audio(sampling_rate=16000))\n","\n","from datasets import concatenate_datasets\n","\n","combined_train = concatenate_datasets([a['train'], b['train'], c['train']])\n","combined_test = concatenate_datasets([a['test'], b['test'], c['test']])\n","combined_test = combined_test.shuffle(seed=42)\n","combined_valid = concatenate_datasets([a['validation'], b['validation'], c['validation']])\n","\n","combined_dataset = IterableDatasetDict({\n","    'train': combined_train,\n","    \"validation\": combined_valid,\n","    'test': combined_test\n","})\n","\n","dataset = combined_dataset\n","print(dataset)"]},{"cell_type":"markdown","metadata":{},"source":["## Loading Greek GPT-2 "]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2025-08-26T19:08:28.889312Z","iopub.status.busy":"2025-08-26T19:08:28.889092Z","iopub.status.idle":"2025-08-26T19:09:16.868900Z","shell.execute_reply":"2025-08-26T19:09:16.865398Z","shell.execute_reply.started":"2025-08-26T19:08:28.889294Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2025-08-26 19:08:47.197211: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1756235327.550338      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1756235327.648106      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3ffbe0ab162340609f127dcd2a26ff61","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/610 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e25365931a744dd1b1249c3c212b4753","version_major":2,"version_minor":0},"text/plain":["vocab.json: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"86eb985b1cf243549bdb1934c9323f75","version_major":2,"version_minor":0},"text/plain":["merges.txt: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"53f86261e8aa48eea2e011bd94d13bf4","version_major":2,"version_minor":0},"text/plain":["tokenizer.json: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"57c84538891f43a8a441eb8b62876c76","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/470 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3b107e45f58041ff9204cd8466b7acd9","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/822 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4b2a8d9c8fbf4d1483635c591731f994","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/510M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"130a5f506a27491b97cdc6cf610a086d","version_major":2,"version_minor":0},"text/plain":["adapter_config.json:   0%|          | 0.00/788 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8c5cf2ead67e493b9574d30e861c5ade","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/510M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1fa1ce3d391141c09c769d50d896eb10","version_major":2,"version_minor":0},"text/plain":["adapter_model.safetensors:   0%|          | 0.00/6.50M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["PeftModelForCausalLM(\n","  (base_model): LoraModel(\n","    (model): GPT2LMHeadModel(\n","      (transformer): GPT2Model(\n","        (wte): Embedding(50257, 768)\n","        (wpe): Embedding(1024, 768)\n","        (drop): Dropout(p=0.1, inplace=False)\n","        (h): ModuleList(\n","          (0-11): 12 x GPT2Block(\n","            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (attn): GPT2Attention(\n","              (c_attn): lora.Linear(\n","                (base_layer): Conv1D(nf=2304, nx=768)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=768, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=2304, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (c_proj): lora.Linear(\n","                (base_layer): Conv1D(nf=768, nx=768)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=768, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=768, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (attn_dropout): Dropout(p=0.1, inplace=False)\n","              (resid_dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (mlp): GPT2MLP(\n","              (c_fc): Conv1D(nf=3072, nx=768)\n","              (c_proj): lora.Linear(\n","                (base_layer): Conv1D(nf=768, nx=3072)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=3072, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=768, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (act): NewGELUActivation()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n","    )\n","  )\n",")"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","import gc\n","import math\n","import numpy as np\n","from tqdm import tqdm\n","from transformers import AutoProcessor, WhisperForConditionalGeneration, AutoTokenizer, AutoModelForCausalLM, WhisperProcessor\n","from peft import PeftModel, PeftConfig\n","import string\n","import re\n","import evaluate\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","\n","lm_tokenizer = AutoTokenizer.from_pretrained(\"Vardis/Medical_Speech_Greek_GPT2\")\n","base_model = AutoModelForCausalLM.from_pretrained(\n","    \"lighteternal/gpt2-finetuned-greek\",\n","    torch_dtype=torch.float16, \n","    device_map=\"auto\"\n",")\n","# LoRA weights\n","lm_model = PeftModel.from_pretrained(base_model, \"Vardis/Medical_Speech_Greek_GPT2\").to(device)\n","\n","lm_model.to(device)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Small Pipeline"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2025-08-25T19:52:38.624412Z","iopub.status.busy":"2025-08-25T19:52:38.623584Z","iopub.status.idle":"2025-08-25T22:10:18.418713Z","shell.execute_reply":"2025-08-25T22:10:18.418131Z","shell.execute_reply.started":"2025-08-25T19:52:38.624377Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1334/1334 [2:17:33<00:00,  6.19s/it] \n"]},{"name":"stdout","output_type":"stream","text":["Average Default Perplexity: 1035.33\n","Average Reranked Perplexity: 888.52\n","Global Default WER: 30.3130\n","Global Reranked WER: 27.3895\n","Global Default Normalized WER: 26.5397\n","Global Reranked Normalized WER: 23.5772\n","Global Default CER: 13.2758\n","Global Reranked CER: 11.8036\n","Average Default BLEU: 0.8235\n","Average Reranked BLEU: 0.8417\n"]}],"source":["import math\n","import numpy as np\n","from tqdm import tqdm\n","from transformers import AutoProcessor, WhisperForConditionalGeneration, AutoTokenizer, AutoModelForCausalLM, WhisperProcessor\n","from peft import PeftModel, PeftConfig\n","import string\n","import re\n","import evaluate\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","\n","base_whisper = WhisperForConditionalGeneration.from_pretrained(\n","    \"openai/whisper-small\",\n","    torch_dtype=torch.float16,\n","    device_map=\"auto\"\n",")\n","\n","# LoRA weights\n","ft_whisper = PeftModel.from_pretrained(\n","    base_whisper, \n","    \"Vardis/Whisper-Small-Greek\"\n",")\n","\n","# Merge LoRA → base weights\n","whisper_model = ft_whisper.merge_and_unload().to(device)\n","\n","processor = WhisperProcessor.from_pretrained(\"Vardis/Whisper-Small-Greek\")\n","whisper_model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"el\", task=\"transcribe\")\n","\n","whisper_model.to(device)\n","\n","def calculate_perplexity(sentence, model, tokenizer, device):\n","    \"\"\"Calculate loss of a sentence using the LM.\"\"\"\n","    model.eval()\n","    inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n","    input_ids = inputs.input_ids\n","    labels = input_ids.clone()\n","    labels[labels == tokenizer.pad_token_id] = -100\n","    with torch.no_grad():\n","        outputs = model(input_ids, labels=labels)\n","        loss = outputs.loss.item()\n","    return math.exp(loss) \n","\n","def get_whisper_transcriptions(audio_array, sr, n_best=5):\n","    input_features = processor(audio_array, sampling_rate=sr, return_tensors=\"pt\").input_features.to(device, dtype=whisper_model.dtype)\n","\n","    with torch.no_grad():\n","        pred_ids = whisper_model.generate(\n","            input_features,\n","            max_length=225,  \n","            num_beams=1,     # Explicitly enforce greedy decoding\n","            do_sample=False  \n","        )\n","    default_transcription = processor.batch_decode(pred_ids, skip_special_tokens=True)[0]\n","\n","    # N-best hypotheses (beam search)\n","    beam_outputs = whisper_model.generate(\n","        input_features,\n","        num_beams=n_best,\n","        num_return_sequences=n_best,\n","        return_dict_in_generate=True,\n","        max_length=225 \n","    )\n","    n_best_transcriptions = processor.batch_decode(beam_outputs.sequences, skip_special_tokens=True)\n","    \n","    return default_transcription, n_best_transcriptions\n","\n","def rerank_hypotheses(hypotheses, model, tokenizer, device):\n","    \"\"\"Rerank hypotheses by LM perplexity and return the best one.\"\"\"\n","    perplexities = [calculate_perplexity(hyp, model, tokenizer, device) for hyp in hypotheses]\n","    best_index = perplexities.index(min(perplexities))\n","    return hypotheses[best_index], perplexities[best_index]\n","\n","smooth_fn = SmoothingFunction().method1\n","\n","wer_metric = evaluate.load(\"wer\")\n","cer_metric = evaluate.load(\"cer\")\n","\n","def normalize_text(text):\n","    \"\"\"Normalize text for WER computation: lowercase, remove punctuation, standardize whitespace.\"\"\"\n","    text = text.lower()\n","    text = re.sub(f\"[{string.punctuation}]\", \"\", text)\n","    text = re.sub(r\"\\s+\", \" \", text).strip()\n","    return text\n","\n","def compute_wer(references, hypotheses):\n","    if len(references) != len(hypotheses):\n","        raise ValueError(\"References and hypotheses must have the same length\")\n","    wer_score = wer_metric.compute(predictions=hypotheses, references=references)\n","    return 100 * wer_score\n","\n","def compute_normalized_wer(references, hypotheses):\n","    \"\"\"Compute WER after normalizing references and hypotheses.\"\"\"\n","    normalized_refs = [normalize_text(ref) for ref in references]\n","    normalized_hyps = [normalize_text(hyp) for hyp in hypotheses]\n","    wer_score = wer_metric.compute(predictions=normalized_hyps, references=normalized_refs)\n","    return 100 * wer_score\n","\n","def compute_cer(references, hypotheses):\n","    if len(references) != len(hypotheses):\n","        raise ValueError(\"References and hypotheses must have the same length\")\n","    cer_score = cer_metric.compute(predictions=hypotheses, references=references)\n","    return 100 * cer_score\n","\n","def compute_bleu(reference, hypothesis):\n","    ref_tokens = list(reference)\n","    hyp_tokens = list(hypothesis)\n","    return sentence_bleu([ref_tokens], hyp_tokens, smoothing_function=smooth_fn)\n","\n","default_perps, reranked_perps = [], []\n","default_preds, reranked_preds = [], []\n","references = []\n","\n","\n","for i, item in enumerate(tqdm(dataset[\"test\"])):\n","    \n","    audio_array = item[\"audio\"][\"array\"]\n","    sampling_rate = item[\"audio\"][\"sampling_rate\"]\n","    ground_truth = item[\"sentence\"]\n","\n","    # Get Whisper transcriptions\n","    default_trans, n_best_hyps = get_whisper_transcriptions(audio_array, sampling_rate, n_best=5)\n","\n","    # Without reranking\n","    default_perp = calculate_perplexity(default_trans, lm_model, lm_tokenizer, device)\n","\n","    # With reranking\n","    reranked_trans, reranked_perp = rerank_hypotheses(n_best_hyps, lm_model, lm_tokenizer, device)\n","\n","    references.append(ground_truth)\n","    default_preds.append(default_trans)\n","    reranked_preds.append(reranked_trans)\n","\n","    default_perps.append(default_perp)\n","    reranked_perps.append(reranked_perp)\n","\n","avg_default_perp = np.mean(default_perps)\n","avg_reranked_perp = np.mean(reranked_perps)\n","\n","avg_default_wer = compute_wer(references, default_preds)\n","avg_reranked_wer = compute_wer(references, reranked_preds)\n","avg_default_normalized_wer = compute_normalized_wer(references, default_preds)\n","avg_reranked_normalized_wer = compute_normalized_wer(references, reranked_preds)\n","\n","avg_default_cer = compute_cer(references, default_preds)\n","avg_reranked_cer = compute_cer(references, reranked_preds)\n","\n","default_bleus = [compute_bleu(ref, hyp) for ref, hyp in zip(references, default_preds)]\n","reranked_bleus = [compute_bleu(ref, hyp) for ref, hyp in zip(references, reranked_preds)]\n","avg_default_bleu = np.mean(default_bleus)\n","avg_reranked_bleu = np.mean(reranked_bleus)\n","\n","print(f\"Average Default Perplexity: {avg_default_perp:.2f}\")\n","print(f\"Average Reranked Perplexity: {avg_reranked_perp:.2f}\")\n","print(f\"Global Default WER: {avg_default_wer:.4f}\")\n","print(f\"Global Reranked WER: {avg_reranked_wer:.4f}\")\n","print(f\"Global Default Normalized WER: {avg_default_normalized_wer:.4f}\")\n","print(f\"Global Reranked Normalized WER: {avg_reranked_normalized_wer:.4f}\")\n","print(f\"Global Default CER: {avg_default_cer:.4f}\")\n","print(f\"Global Reranked CER: {avg_reranked_cer:.4f}\")\n","print(f\"Average Default BLEU: {avg_default_bleu:.4f}\")\n","print(f\"Average Reranked BLEU: {avg_reranked_bleu:.4f}\")\n","\n","gc.collect()\n","torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{},"source":["## Medium Pipeline"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2025-08-26T13:25:54.382459Z","iopub.status.busy":"2025-08-26T13:25:54.381700Z","iopub.status.idle":"2025-08-26T18:45:37.336763Z","shell.execute_reply":"2025-08-26T18:45:37.336011Z","shell.execute_reply.started":"2025-08-26T13:25:54.382430Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1334/1334 [5:19:34<00:00, 14.37s/it]  \n"]},{"name":"stdout","output_type":"stream","text":["Average Default Perplexity: 518.27\n","Average Reranked Perplexity: 378.11\n","Global Default WER: 19.4459\n","Global Reranked WER: 18.2357\n","Global Default Normalized WER: 16.1724\n","Global Reranked Normalized WER: 14.8634\n","Global Default CER: 8.9602\n","Global Reranked CER: 8.3561\n","Average Default BLEU: 0.8893\n","Average Reranked BLEU: 0.8960\n"]}],"source":["base_whisper = WhisperForConditionalGeneration.from_pretrained(\n","    \"openai/whisper-medium\",\n","    torch_dtype=torch.float16,\n","    device_map=\"auto\"\n",")\n","\n","ft_whisper = PeftModel.from_pretrained(\n","    base_whisper, \n","    \"Vardis/Whisper-Medium-Greek\"\n",")\n","\n","whisper_model = ft_whisper.merge_and_unload().to(device)\n","\n","processor = WhisperProcessor.from_pretrained(\"Vardis/Whisper-Medium-Greek\")\n","whisper_model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"el\", task=\"transcribe\")\n","\n","whisper_model.to(device)\n","\n","def calculate_perplexity(sentence, model, tokenizer, device):\n","    \"\"\"Calculate loss of a sentence using the LM.\"\"\"\n","    model.eval()\n","    inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n","    input_ids = inputs.input_ids\n","    labels = input_ids.clone()\n","    labels[labels == tokenizer.pad_token_id] = -100\n","    with torch.no_grad():\n","        outputs = model(input_ids, labels=labels)\n","        loss = outputs.loss.item()\n","    return math.exp(loss) \n","\n","def get_whisper_transcriptions(audio_array, sr, n_best=5):\n","    input_features = processor(audio_array, sampling_rate=sr, return_tensors=\"pt\").input_features.to(device, dtype=whisper_model.dtype)\n","\n","    with torch.no_grad():\n","        pred_ids = whisper_model.generate(\n","            input_features,\n","            max_length=225,  \n","            num_beams=1,     # Explicitly enforce greedy decoding\n","            do_sample=False  \n","        )\n","    default_transcription = processor.batch_decode(pred_ids, skip_special_tokens=True)[0]\n","\n","    # N-best hypotheses (beam search)\n","    beam_outputs = whisper_model.generate(\n","        input_features,\n","        num_beams=n_best,\n","        num_return_sequences=n_best,\n","        return_dict_in_generate=True,\n","        max_length=225 \n","    )\n","    n_best_transcriptions = processor.batch_decode(beam_outputs.sequences, skip_special_tokens=True)\n","    \n","    return default_transcription, n_best_transcriptions\n","\n","def rerank_hypotheses(hypotheses, model, tokenizer, device):\n","    \"\"\"Rerank hypotheses by LM perplexity and return the best one.\"\"\"\n","    perplexities = [calculate_perplexity(hyp, model, tokenizer, device) for hyp in hypotheses]\n","    best_index = perplexities.index(min(perplexities))\n","    return hypotheses[best_index], perplexities[best_index]\n","\n","smooth_fn = SmoothingFunction().method1\n","\n","wer_metric = evaluate.load(\"wer\")\n","cer_metric = evaluate.load(\"cer\")\n","\n","def normalize_text(text):\n","    \"\"\"Normalize text for WER computation: lowercase, remove punctuation, standardize whitespace.\"\"\"\n","    text = text.lower()\n","    text = re.sub(f\"[{string.punctuation}]\", \"\", text)\n","    text = re.sub(r\"\\s+\", \" \", text).strip()\n","    return text\n","\n","def compute_wer(references, hypotheses):\n","    if len(references) != len(hypotheses):\n","        raise ValueError(\"References and hypotheses must have the same length\")\n","    wer_score = wer_metric.compute(predictions=hypotheses, references=references)\n","    return 100 * wer_score\n","\n","def compute_normalized_wer(references, hypotheses):\n","    \"\"\"Compute WER after normalizing references and hypotheses.\"\"\"\n","    normalized_refs = [normalize_text(ref) for ref in references]\n","    normalized_hyps = [normalize_text(hyp) for hyp in hypotheses]\n","    wer_score = wer_metric.compute(predictions=normalized_hyps, references=normalized_refs)\n","    return 100 * wer_score\n","\n","def compute_cer(references, hypotheses):\n","    if len(references) != len(hypotheses):\n","        raise ValueError(\"References and hypotheses must have the same length\")\n","    cer_score = cer_metric.compute(predictions=hypotheses, references=references)\n","    return 100 * cer_score\n","\n","def compute_bleu(reference, hypothesis):\n","    ref_tokens = list(reference)\n","    hyp_tokens = list(hypothesis)\n","    return sentence_bleu([ref_tokens], hyp_tokens, smoothing_function=smooth_fn)\n","\n","default_perps, reranked_perps = [], []\n","default_preds, reranked_preds = [], []\n","references = []\n","\n","    \n","for i, item in enumerate(tqdm(dataset[\"test\"])):\n","   \n","    audio_array = item[\"audio\"][\"array\"]\n","    sampling_rate = item[\"audio\"][\"sampling_rate\"]\n","    ground_truth = item[\"sentence\"]\n","\n","    # Get Whisper transcriptions\n","    default_trans, n_best_hyps = get_whisper_transcriptions(audio_array, sampling_rate, n_best=5)\n","\n","    # Without reranking\n","    default_perp = calculate_perplexity(default_trans, lm_model, lm_tokenizer, device)\n","\n","    # With reranking\n","    reranked_trans, reranked_perp = rerank_hypotheses(n_best_hyps, lm_model, lm_tokenizer, device)\n","\n","    references.append(ground_truth)\n","    default_preds.append(default_trans)\n","    reranked_preds.append(reranked_trans)\n","\n","    default_perps.append(default_perp)\n","    reranked_perps.append(reranked_perp)\n","\n","avg_default_perp = np.mean(default_perps)\n","avg_reranked_perp = np.mean(reranked_perps)\n","\n","avg_default_wer = compute_wer(references, default_preds)\n","avg_reranked_wer = compute_wer(references, reranked_preds)\n","avg_default_normalized_wer = compute_normalized_wer(references, default_preds)\n","avg_reranked_normalized_wer = compute_normalized_wer(references, reranked_preds)\n","\n","avg_default_cer = compute_cer(references, default_preds)\n","avg_reranked_cer = compute_cer(references, reranked_preds)\n","\n","default_bleus = [compute_bleu(ref, hyp) for ref, hyp in zip(references, default_preds)]\n","reranked_bleus = [compute_bleu(ref, hyp) for ref, hyp in zip(references, reranked_preds)]\n","avg_default_bleu = np.mean(default_bleus)\n","avg_reranked_bleu = np.mean(reranked_bleus)\n","\n","print(f\"Average Default Perplexity: {avg_default_perp:.2f}\")\n","print(f\"Average Reranked Perplexity: {avg_reranked_perp:.2f}\")\n","print(f\"Global Default WER: {avg_default_wer:.4f}\")\n","print(f\"Global Reranked WER: {avg_reranked_wer:.4f}\")\n","print(f\"Global Default Normalized WER: {avg_default_normalized_wer:.4f}\")\n","print(f\"Global Reranked Normalized WER: {avg_reranked_normalized_wer:.4f}\")\n","print(f\"Global Default CER: {avg_default_cer:.4f}\")\n","print(f\"Global Reranked CER: {avg_reranked_cer:.4f}\")\n","print(f\"Average Default BLEU: {avg_default_bleu:.4f}\")\n","print(f\"Average Reranked BLEU: {avg_reranked_bleu:.4f}\")\n","\n","gc.collect()\n","torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{},"source":["## Large Pipeline"]},{"cell_type":"code","execution_count":4,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-08-26T19:09:16.889295Z","iopub.status.busy":"2025-08-26T19:09:16.888918Z","iopub.status.idle":"2025-08-27T03:45:13.364586Z","shell.execute_reply":"2025-08-27T03:45:13.363873Z","shell.execute_reply.started":"2025-08-26T19:09:16.889257Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a49b5538e7d340a6a510f82237776da7","version_major":2,"version_minor":0},"text/plain":["config.json: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5fe189fec848464a8dd3934191918eda","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/6.17G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9bc1644709e94e25b22cd57fb68ca080","version_major":2,"version_minor":0},"text/plain":["generation_config.json: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bcf6ee91db8b42fbb1b49d194cd03cbf","version_major":2,"version_minor":0},"text/plain":["adapter_config.json:   0%|          | 0.00/931 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b265ca0eefb4449fb36e6ae89624baec","version_major":2,"version_minor":0},"text/plain":["adapter_model.safetensors:   0%|          | 0.00/126M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7278222f71b34b0f876471838dd1b4c5","version_major":2,"version_minor":0},"text/plain":["preprocessor_config.json:   0%|          | 0.00/356 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ab2b158607c149829ff90f7e709f7d6a","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fe7065276f27437bba8963ff217df91a","version_major":2,"version_minor":0},"text/plain":["vocab.json: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5c919370f8cb4c67a25473c15d8148cf","version_major":2,"version_minor":0},"text/plain":["merges.txt: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ef82640a3b3c41c0adad0595f6064c81","version_major":2,"version_minor":0},"text/plain":["normalizer.json: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"140bde421b3f4701b7bf331fed67e6fe","version_major":2,"version_minor":0},"text/plain":["added_tokens.json: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"72b731c8e3854475a70641108b58bc0c","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7093a441e2b049f5ad086a33f3bcfe74","version_major":2,"version_minor":0},"text/plain":["Downloading builder script: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"81b41f59839e442da1da9451827dadb6","version_major":2,"version_minor":0},"text/plain":["Downloading builder script: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/1334 [00:00<?, ?it/s]Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n","The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n","100%|██████████| 1334/1334 [8:34:48<00:00, 23.16s/it]  \n"]},{"name":"stdout","output_type":"stream","text":["Average Default Perplexity: nan\n","Average Reranked Perplexity: 234.60\n","Global Default WER: 14.9019\n","Global Reranked WER: 14.6952\n","Global Default Normalized WER: 12.0567\n","Global Reranked Normalized WER: 11.9818\n","Global Default CER: 8.4469\n","Global Reranked CER: 8.6675\n","Average Default BLEU: 0.9203\n","Average Reranked BLEU: 0.9206\n"]}],"source":["\n","\n","base_whisper = WhisperForConditionalGeneration.from_pretrained(\n","    \"openai/whisper-large-v2\",\n","    torch_dtype=torch.float16,\n","    device_map=\"auto\"\n",")\n","\n","ft_whisper = PeftModel.from_pretrained(\n","    base_whisper, \n","    \"Vardis/Whisper-Large-v2-Greek\"\n",")\n","\n","whisper_model = ft_whisper.merge_and_unload().to(device)\n","\n","processor = WhisperProcessor.from_pretrained(\"Vardis/Whisper-Large-v2-Greek\")\n","whisper_model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"el\", task=\"transcribe\")\n","\n","\n","whisper_model.to(device)\n","\n","def calculate_perplexity(sentence, model, tokenizer, device):\n","    \"\"\"Calculate loss of a sentence using the LM.\"\"\"\n","    model.eval()\n","    inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n","    input_ids = inputs.input_ids\n","    labels = input_ids.clone()\n","    labels[labels == tokenizer.pad_token_id] = -100\n","    with torch.no_grad():\n","        outputs = model(input_ids, labels=labels)\n","        loss = outputs.loss.item()\n","    return math.exp(loss) \n","\n","def get_whisper_transcriptions(audio_array, sr, n_best=5):\n","    input_features = processor(audio_array, sampling_rate=sr, return_tensors=\"pt\").input_features.to(device, dtype=whisper_model.dtype)\n","\n","    with torch.no_grad():\n","        pred_ids = whisper_model.generate(\n","            input_features,\n","            max_length=225,  \n","            num_beams=1,     \n","            do_sample=False  \n","        )\n","    default_transcription = processor.batch_decode(pred_ids, skip_special_tokens=True)[0]\n","\n","    beam_outputs = whisper_model.generate(\n","        input_features,\n","        num_beams=n_best,\n","        num_return_sequences=n_best,\n","        return_dict_in_generate=True,\n","        max_length=225  \n","    )\n","    n_best_transcriptions = processor.batch_decode(beam_outputs.sequences, skip_special_tokens=True)\n","    \n","    return default_transcription, n_best_transcriptions\n","\n","def rerank_hypotheses(hypotheses, model, tokenizer, device):\n","    \"\"\"Rerank hypotheses by LM perplexity and return the best one.\"\"\"\n","    perplexities = [calculate_perplexity(hyp, model, tokenizer, device) for hyp in hypotheses]\n","    best_index = perplexities.index(min(perplexities))\n","    return hypotheses[best_index], perplexities[best_index]\n","\n","smooth_fn = SmoothingFunction().method1\n","\n","wer_metric = evaluate.load(\"wer\")\n","cer_metric = evaluate.load(\"cer\")\n","\n","def normalize_text(text):\n","    \"\"\"Normalize text for WER computation: lowercase, remove punctuation, standardize whitespace.\"\"\"\n","    text = text.lower()\n","    text = re.sub(f\"[{string.punctuation}]\", \"\", text)\n","    text = re.sub(r\"\\s+\", \" \", text).strip()\n","    return text\n","\n","def compute_wer(references, hypotheses):\n","    if len(references) != len(hypotheses):\n","        raise ValueError(\"References and hypotheses must have the same length\")\n","    wer_score = wer_metric.compute(predictions=hypotheses, references=references)\n","    return 100 * wer_score\n","\n","def compute_normalized_wer(references, hypotheses):\n","    \"\"\"Compute WER after normalizing references and hypotheses.\"\"\"\n","    normalized_refs = [normalize_text(ref) for ref in references]\n","    normalized_hyps = [normalize_text(hyp) for hyp in hypotheses]\n","    wer_score = wer_metric.compute(predictions=normalized_hyps, references=normalized_refs)\n","    return 100 * wer_score\n","\n","def compute_cer(references, hypotheses):\n","    if len(references) != len(hypotheses):\n","        raise ValueError(\"References and hypotheses must have the same length\")\n","    cer_score = cer_metric.compute(predictions=hypotheses, references=references)\n","    return 100 * cer_score\n","\n","def compute_bleu(reference, hypothesis):\n","    ref_tokens = list(reference)\n","    hyp_tokens = list(hypothesis)\n","    return sentence_bleu([ref_tokens], hyp_tokens, smoothing_function=smooth_fn)\n","\n","default_perps, reranked_perps = [], []\n","default_preds, reranked_preds = [], []\n","references = []\n","\n","for i, item in enumerate(tqdm(dataset[\"test\"])):\n","    \n","        \n","    audio_array = item[\"audio\"][\"array\"]\n","    sampling_rate = item[\"audio\"][\"sampling_rate\"]\n","    ground_truth = item[\"sentence\"]\n","\n","    # Get Whisper transcriptions\n","    default_trans, n_best_hyps = get_whisper_transcriptions(audio_array, sampling_rate, n_best=5)\n","\n","    # Without reranking\n","    default_perp = calculate_perplexity(default_trans, lm_model, lm_tokenizer, device)\n","\n","    # With reranking\n","    reranked_trans, reranked_perp = rerank_hypotheses(n_best_hyps, lm_model, lm_tokenizer, device)\n","\n","    references.append(ground_truth)\n","    default_preds.append(default_trans)\n","    reranked_preds.append(reranked_trans)\n","\n","    default_perps.append(default_perp)\n","    reranked_perps.append(reranked_perp)\n","\n","avg_default_perp = np.mean(default_perps)\n","avg_reranked_perp = np.mean(reranked_perps)\n","\n","avg_default_wer = compute_wer(references, default_preds)\n","avg_reranked_wer = compute_wer(references, reranked_preds)\n","avg_default_normalized_wer = compute_normalized_wer(references, default_preds)\n","avg_reranked_normalized_wer = compute_normalized_wer(references, reranked_preds)\n","\n","avg_default_cer = compute_cer(references, default_preds)\n","avg_reranked_cer = compute_cer(references, reranked_preds)\n","\n","default_bleus = [compute_bleu(ref, hyp) for ref, hyp in zip(references, default_preds)]\n","reranked_bleus = [compute_bleu(ref, hyp) for ref, hyp in zip(references, reranked_preds)]\n","avg_default_bleu = np.mean(default_bleus)\n","avg_reranked_bleu = np.mean(reranked_bleus)\n","\n","print(f\"Average Default Perplexity: {avg_default_perp:.2f}\")\n","print(f\"Average Reranked Perplexity: {avg_reranked_perp:.2f}\")\n","print(f\"Global Default WER: {avg_default_wer:.4f}\")\n","print(f\"Global Reranked WER: {avg_reranked_wer:.4f}\")\n","print(f\"Global Default Normalized WER: {avg_default_normalized_wer:.4f}\")\n","print(f\"Global Reranked Normalized WER: {avg_reranked_normalized_wer:.4f}\")\n","print(f\"Global Default CER: {avg_default_cer:.4f}\")\n","print(f\"Global Reranked CER: {avg_reranked_cer:.4f}\")\n","print(f\"Average Default BLEU: {avg_default_bleu:.4f}\")\n","print(f\"Average Reranked BLEU: {avg_reranked_bleu:.4f}\")\n","\n","gc.collect()\n","torch.cuda.empty_cache()"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"}},"nbformat":4,"nbformat_minor":4}
