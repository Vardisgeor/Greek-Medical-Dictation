Whisper-Small-Greek
===================

Description
-----------
This is the Small version of Whisper fine-tuned for Greek automatic speech recognition (ASR).

Details
-------
- Base Model: OpenAI Whisper Small (244M parameters)
- Method: LoRA fine-tuning (PEFT)
- Language: Greek
- Datasets: Greek Mosel, Common Voice 11.0 (Greek), Google Fleurs (Greek)

Results
-------
- WER: 26.99%
- CER: 11.10%

How to Use
----------
from transformers import WhisperProcessor, WhisperForConditionalGeneration
from peft import PeftModel
import torch

device = "cuda" if torch.cuda.is_available() else "cpu"

# Load base model
base_model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-small").to(device)

# Load LoRA weights
model = PeftModel.from_pretrained(base_model, "Vardis/Whisper-Small-Greek").to(device)

# Load processor
processor = WhisperProcessor.from_pretrained("Vardis/Whisper-Small-Greek")

# Example inference
audio_input = ...  # waveform array
inputs = processor(audio_input, return_tensors="pt").input_features.to(device)
predicted_ids = model.generate(inputs)
print(processor.batch_decode(predicted_ids, skip_special_tokens=True))
